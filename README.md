Fine-Tuning an LLM on Amazon SageMaker

Description: Simulated business scenario: The city's AI Hub understands the unique insights that their internal data offers. They plan to use this specific data to optimize generative AI models on AWS, ensuring that the models are tailored to local challenges. Their goal is to develop a secure and scalable solution that provides rapid inferencing, driving growth, and keeping them at the forefront of AI technology.

Overview: In this AWS SimuLearn assignment, you review a real-world scenario, helping a fictional customer design a solution on AWS. After the design is completed, you build the proposed solution in a guided lab within a live AWS Management Console environment. You gain hands-on experience working with AWS services, using the same tools technology professionals use to construct AWS solutions.

Objectives: Identify the key features of Amazon Bedrock, Amazon Kendra, and AWS serverless services. Explain the concept of Retrieval Augmented Generation (RAG) and how it applies to building an AI-powered chatbot. Determine how to use Amazon Bedrock and Amazon Kendra to index and retrieve data from a knowledge base for chatbot interactions. Demonstrate how to construct a fully functional generative AI-powered chatbot for a specific use case, integrating Amazon serverless services to efficiently handle application code execution.

AWS Services: AWS Amplify, Amazon API Gateway, Amazon Bedrock, AWS CloudFormation, Amazon CloudFront, Amazon Cognito, AWS Lambda, Amazon Simple Storage Service.

My architecture:
<img width="1440" height="860" alt="Fine-Tuning-an-LLM-on-Amazon-SageMaker" src="https://github.com/user-attachments/assets/caf12fb7-f1b5-4e03-aa85-6d692e643346" />

Proof of completion:
<img width="1152" height="896" alt="FIne-tuning-LLM-kartik_Patil" src="https://github.com/user-attachments/assets/9c552675-3b47-4052-a105-862963c4647a" />

